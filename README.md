# Task Arithmetic Through The Lens Of One-Shot Federated Learning

This repository contains code for the paper [Task Arithmetic Through The Lens Of One-Shot Federated Learning](https://arxiv.org/abs/2411.18607). It is built upon the [repository](https://github.com/mlfoundations/task_vectors) for the paper [Editing Models With Task Arithmetic](https://arxiv.org/abs/2212.04089) and follows the same structure. 

## Dependencies
To run the code, please first install all dependencies and add directory to PYTHONPATH.

```
conda env create 
conda activate one_shot_fl_ta
cd one_shot_fl_task_arithmetic
export PYTHONPATH="$PYTHONPATH:$PWD"
```

## Fine-tuning
The module ```src/finetune.py``` is used to fine-tune models on downstream tasks. Below is an example of fine-tuning:

```
from src.finetune import finetune
from src.args import parse_arguments

args = parse_arguments()
args.train_dataset = 'MNISTVal' # For fine-tuning, append 'Val' to the dataset name
args.data_location = '/path/to/MNIST'
args.lr = 1e-5
args.epochs = 5
args.batch_size = 128
args.model = 'ViT-B-32'
arg.save = '/path/to/save/checkpoints'
finetune(args)
```

## Task Vectors
The process of creating and using task vectors follows the original [repository](https://github.com/mlfoundations/task_vectors). Please refer to it for more details. 

## Model Merging Methods
In this work, we implemented Task Arithmetic and its variants based on four Federated Learning algorithms: [FedNova](https://arxiv.org/abs/2007.07481), [FedGMA](https://arxiv.org/abs/2201.11986), [Median](https://arxiv.org/abs/1803.01498) and [CCLIP](https://arxiv.org/abs/2012.10333). The module ```src/ta_algorithms.py``` contains the implementation of all these algorithms, as well as the code for searching the best hyperparameters for each.

### Generating new task vectors
To run FedNova, provide a list of task vectors along with a corresponding list of the number of iterations used to train each task vector. In this work, we implemented a simplified version of FedNova by normalizing each task vector based solely on the number of training iterations. For the full algorithm, please refer to the original [paper](https://arxiv.org/pdf/2007.07481).

```
from src.ta_algorithms import fednova

task_vectors = [list of task vectors]
local_steps [list of the number of local steps used to train each task vector]
new_task_vector = fednova(task_vectors, local_steps) # new merged task vector generated by using FedNova
```

To run FedGMA, provide a list of task vectors and a value for the hyperparameter $\rho$. 

```
from src.ta_algorithms import fedgma

task_vectors = [list of task vectors]
rho = ... # threshold to construct a mask
new_task_vector = fedgma(task_vectors, rho)
```

To run Median, provide a list of task vectors. 

```
from src.ta_algorithms import median_of_tvs

task_vectors = [list of task vectors]
new_task_vector = median_of_tvs(task_vectors)
```

To run CCLIP, provide a list of task vectors and a value for the hyperparameter $\rho$.

```
from src.ta_algorithms import cclip

task_vectors = [list of task vectors]
rho = ... # threshold to clip task vectors
new_task_vector = cclip(task_vectors, rho)
```

### Applying task vectors to models
To obatin the final model, first compute the new task vector using one of the supported algorithms. Then apply the new task vector back to a pre-trained model using a scaling coefficient. 

```
from src.task_vectors import TaskVector

scaling_coef = ... 
pretrained_checkpoint = torch.load('/path/to/the/checkpoint')
new_model = new_task_vector.apply_to(pretrained_checkpoint, scaling_coef)
```

### Hyperparameter search
For FedNova and Median, the only hyperparameter to tune is the scaling coefficient used when applying the new task vector to the pretrained model. Below is an example of how to search for the optimal scaling coefficient.

```
```

For FedGMA and CCLIP, in addition to the scaling coefficient, you also need to tune the hyperparameter $\rho$. We provide code to search for the best combination of $\rho$ and the scaling coefficient for both methods.

```
```
